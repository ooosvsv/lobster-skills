#!/usr/bin/env python3
"""Exa AI æœç´¢å¼•æ“ - è¯­ä¹‰æœç´¢å¢å¼ºç‰ˆ"""

import json
import urllib.request
import sys
import argparse
import os

EXA_API_KEY = os.environ.get("EXA_API_KEY", "")
EXA_API_URL = "https://api.exa.ai/search"

def search_exa(query, num_results=10, category=None, livecrawl=False):
    """
    è°ƒç”¨ Exa AI æœç´¢ API
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        num_results: è¿”å›ç»“æœæ•°é‡ (1-100)
        category: æœç´¢ç±»åˆ« (company, news, research paper, tweet, personal site, financial report)
        livecrawl: æ˜¯å¦å®æ—¶æŠ“å–é¡µé¢å†…å®¹
    """
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {EXA_API_KEY}",
        "User-Agent": "curl/7.68.0"
    }
    
    data = {
        "query": query,
        "numResults": min(max(num_results, 1), 100),
        "type": "auto",
        "contents": {
            "text": True,
            "highlights": True
        }
    }
    
    if category:
        data["category"] = category
    
    if livecrawl:
        data["livecrawl"] = "always"
    
    req = urllib.request.Request(
        EXA_API_URL,
        data=json.dumps(data).encode('utf-8'),
        headers=headers,
        method="POST"
    )
    
    try:
        with urllib.request.urlopen(req, timeout=30) as response:
            return json.loads(response.read().decode('utf-8'))
    except urllib.error.HTTPError as e:
        return {"error": f"HTTP {e.code}: {e.read().decode('utf-8')}"}
    except Exception as e:
        return {"error": str(e)}

def format_results(results):
    """æ ¼å¼åŒ–æœç´¢ç»“æœä¸º Markdown"""
    if "error" in results:
        return f"âŒ æœç´¢å¤±è´¥: {results['error']}"
    
    search_results = results.get("results", [])
    if not search_results:
        return "ğŸ¤· æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœ"
    
    output = [f"### ğŸ” Exa æœç´¢ç»“æœ ({len(search_results)} æ¡)\n"]
    
    for i, result in enumerate(search_results, 1):
        title = result.get("title", "æ— æ ‡é¢˜")
        url = result.get("url", "")
        text = result.get("text", "")
        highlights = result.get("highlights", [])
        
        # æˆªæ–­æ–‡æœ¬
        text_preview = text[:300] + "..." if len(text) > 300 else text
        
        output.append(f"**{i}. [{title}]({url})**")
        output.append(f"> {text_preview}\n")
        
        if highlights:
            output.append(f"ğŸ’¡ äº®ç‚¹: {highlights[0][:150]}...")
        
        output.append("")  # ç©ºè¡Œ
    
    return "\n".join(output)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Exa AI æœç´¢")
    parser.add_argument("query", help="æœç´¢æŸ¥è¯¢")
    parser.add_argument("--num", type=int, default=10, help="ç»“æœæ•°é‡")
    parser.add_argument("--category", choices=["company", "news", "research paper", "tweet", "personal site", "financial report"], help="æœç´¢ç±»åˆ«")
    parser.add_argument("--livecrawl", action="store_true", help="å®æ—¶æŠ“å–é¡µé¢")
    
    args = parser.parse_args()
    
    results = search_exa(args.query, args.num, args.category, args.livecrawl)
    print(format_results(results))
